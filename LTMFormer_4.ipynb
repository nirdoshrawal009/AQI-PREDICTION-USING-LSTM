{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNA7p3dXnov4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import functools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, BatchSampler\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_log_error as msle\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "jGKVK1pSpE5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/Jodhpur_1.csv')\n",
        "df1 = df1[['PM2.5','PM10','SO2','NO2','CO','O3']]\n",
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IgMTfudinvJa",
        "outputId": "a0a25f97-10b2-49bd-e3d5-b6809e4ea971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PM2.5  PM10   SO2    NO2    CO      O3\n",
              "0  41.96  96.4  4.37  17.90  0.17   75.10\n",
              "1  33.22  67.0  2.62  17.79  0.18  103.08\n",
              "2  23.38  51.1  0.74  19.69  0.47   48.62\n",
              "3  21.06  44.3  2.83  15.98  0.34   35.02\n",
              "4  22.89  43.8  3.38  18.25  0.21   16.57"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b110c99e-5cad-4d14-ab64-36151c9c1d51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PM2.5</th>\n",
              "      <th>PM10</th>\n",
              "      <th>SO2</th>\n",
              "      <th>NO2</th>\n",
              "      <th>CO</th>\n",
              "      <th>O3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41.96</td>\n",
              "      <td>96.4</td>\n",
              "      <td>4.37</td>\n",
              "      <td>17.90</td>\n",
              "      <td>0.17</td>\n",
              "      <td>75.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.22</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2.62</td>\n",
              "      <td>17.79</td>\n",
              "      <td>0.18</td>\n",
              "      <td>103.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.38</td>\n",
              "      <td>51.1</td>\n",
              "      <td>0.74</td>\n",
              "      <td>19.69</td>\n",
              "      <td>0.47</td>\n",
              "      <td>48.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.06</td>\n",
              "      <td>44.3</td>\n",
              "      <td>2.83</td>\n",
              "      <td>15.98</td>\n",
              "      <td>0.34</td>\n",
              "      <td>35.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.89</td>\n",
              "      <td>43.8</td>\n",
              "      <td>3.38</td>\n",
              "      <td>18.25</td>\n",
              "      <td>0.21</td>\n",
              "      <td>16.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b110c99e-5cad-4d14-ab64-36151c9c1d51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b110c99e-5cad-4d14-ab64-36151c9c1d51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b110c99e-5cad-4d14-ab64-36151c9c1d51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('/content/Jodhpur_2.csv')\n",
        "df2 = df2[['PM2.5','PM10','SO2','NO2','CO','O3']]\n",
        "df3 = pd.read_csv('/content/Jodhpur_3.csv')\n",
        "df3 = df3[['PM2.5','PM10','SO2','NO2','CO','O3']]\n",
        "df4 = pd.read_csv('/content/Jodhpur_4.csv')\n",
        "df4 = df4[['PM2.5','PM10','SO2','NO2','CO','O3']]"
      ],
      "metadata": {
        "id": "_UomL82-nzEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([df1, df2, df3, df4], axis=0)"
      ],
      "metadata": {
        "id": "QnKwLgNUoSj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDeYYvEqoU7B",
        "outputId": "d40e925e-0c10-4a16-bdfe-c3d674ac31bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26425, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trans:\n",
        "    def __init__(self, data, name):\n",
        "        self.min = max(0, np.percentile(data, 1))\n",
        "        self.max = np.percentile(data, 99)\n",
        "        self.base = self.max-self.min\n",
        "\n",
        "    def transform(self, data, scale=True):\n",
        "        _data = np.clip(data, self.min, self.max)\n",
        "        if not scale:\n",
        "            return _data\n",
        "        return (_data-self.min)/self.base\n",
        "\n",
        "class TransUtil:\n",
        "    def __init__(self, data, exclude_cols=None):\n",
        "        self.columns = data.columns\n",
        "        self.exclude_cols = exclude_cols\n",
        "        self.trans = {}\n",
        "        for c in self.columns:\n",
        "            if data[c].dtype not in [int, float]:\n",
        "                print('column \"{}\" not init trans...'.format(c))\n",
        "                continue\n",
        "\n",
        "            if exclude_cols is None or (exclude_cols is not None and c not in exclude_cols):\n",
        "                print('init trans column...', c)\n",
        "                self.trans[c] = Trans(data[c].fillna(method='backfill').fillna(method='ffill'), c)\n",
        "\n",
        "    def transform(self, data, col_name, scale=True):\n",
        "        if self.exclude_cols is not None and col_name in self.exclude_cols:\n",
        "            return data\n",
        "\n",
        "        for t in self.trans:\n",
        "            if t.startswith(col_name):\n",
        "                return self.trans[t].transform(data, scale=scale)\n",
        "        \n",
        "        return data"
      ],
      "metadata": {
        "id": "i9WXvEt_oWdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_util = TransUtil(final_df, exclude_cols=None) # data standardization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD6DfmJVoYY2",
        "outputId": "e7998e0f-0be5-4709-e415-e0d39c715316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init trans column... PM2.5\n",
            "init trans column... PM10\n",
            "init trans column... SO2\n",
            "init trans column... NO2\n",
            "init trans column... CO\n",
            "init trans column... O3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_xy_pair(final_df, seq_len, trans_util, columns_x, columns_y):\n",
        "    data_x = pd.DataFrame()\n",
        "    for c in columns_x:\n",
        "        data_x[c] = trans_util.transform(final_df[c].fillna(final_df[c].median()), c)\n",
        "\n",
        "    data_y = pd.DataFrame()\n",
        "    for c in columns_y:\n",
        "        data_y[c] = trans_util.transform(final_df[c].fillna(final_df[c].median()), c, scale=False)\n",
        "\n",
        "    data_x = data_x.values\n",
        "    data_y = data_y.values\n",
        "    \n",
        "    print(data_x.shape, data_y.shape)\n",
        "\n",
        "    d_x = []\n",
        "    d_y = []\n",
        "    for i in range(len(data_x)-seq_len*2+1):\n",
        "        _x = data_x[i:i+seq_len]\n",
        "        _y = data_y[i+seq_len:i+seq_len+seq_len]\n",
        "\n",
        "        assert len(_x) == len(_y) == seq_len, (_x, _y, _x.shape, _y.shape, i, len(data_x))\n",
        "\n",
        "        d_x.append(_x.T)\n",
        "        d_y.append(_y.T)\n",
        "\n",
        "    return np.asarray(d_x).transpose((0, 2, 1)), np.asarray(d_y).transpose((0, 2, 1))"
      ],
      "metadata": {
        "id": "zfc_ok_OoaZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN =168"
      ],
      "metadata": {
        "id": "oSgVazKhocHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMNS_Y = ([\"PM2.5\",\"PM10\",\t\"SO2\", \"NO2\",\t\"CO\",\t\"O3\"])\n",
        "COLUMNS_X = COLUMNS_Y\n",
        "COLUMNS_X, COLUMNS_Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjMLsoPdoeDg",
        "outputId": "9259be24-0ba0-4d65-e01f-bf72dc637c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3'],\n",
              " ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_x, data_y = generate_xy_pair(final_df, seq_len=SEQ_LEN, trans_util=trans_util, columns_x=COLUMNS_Y, columns_y=COLUMNS_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egUSdZ5-ofry",
        "outputId": "6f62d2f8-4a19-4b87-9b80-4bd5cd00018a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26425, 6) (26425, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_x.shape, data_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaceP-XKohgY",
        "outputId": "b895b892-c095-4e79-f576-95e62def2b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26090, 168, 6), (26090, 168, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_x[0], data_y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uw4GDYNojWR",
        "outputId": "802c06d1-d08d-4f51-d344-2a55f3e17d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.12481404, 0.14591875, 0.14976392, 0.13948847, 0.03088803,\n",
              "         0.54196938],\n",
              "        [0.09712546, 0.09898208, 0.08791597, 0.1384102 , 0.03281853,\n",
              "         0.75513799],\n",
              "        [0.06595204, 0.07359797, 0.02147361, 0.15703481, 0.08880309,\n",
              "         0.34022868],\n",
              "        ...,\n",
              "        [0.17943087, 0.26820951, 0.12785207, 0.11429624, 0.06756757,\n",
              "         0.22511154],\n",
              "        [0.20715113, 0.27762877, 0.1094744 , 0.08596724, 0.03281853,\n",
              "         0.14961115],\n",
              "        [0.20328613, 0.27778842, 0.08826939, 0.0878297 , 0.05019305,\n",
              "         0.18343776]]),\n",
              " array([[5.503e+01, 1.458e+02, 7.500e-01, 1.152e+01, 7.200e-01, 2.063e+01],\n",
              "        [5.728e+01, 1.508e+02, 2.350e+00, 9.920e+00, 6.100e-01, 1.747e+01],\n",
              "        [4.825e+01, 1.535e+02, 3.890e+00, 1.318e+01, 5.400e-01, 3.069e+01],\n",
              "        ...,\n",
              "        [2.152e+01, 7.910e+01, 5.270e+00, 2.408e+01, 4.000e-01, 1.971e+01],\n",
              "        [4.687e+01, 9.200e+01, 3.750e+00, 2.919e+01, 1.120e+00, 2.070e+01],\n",
              "        [6.275e+01, 1.018e+02, 1.324e-01, 3.008e+01, 7.200e-01, 1.269e+01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9SDg3sFnondN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "4HgLq6MXouEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlVnhWdPov8F",
        "outputId": "5afbfb55-eb43-4bd6-d97c-de62a5695e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17480, 168, 6), (8610, 168, 6), (17480, 168, 6), (8610, 168, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXEr3ig8ozBV",
        "outputId": "5d8209cf-4b79-42a7-b343-5a53b18d549b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(168, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "X_test = np.array(X_test, dtype=np.float)\n",
        "y_test = np.array(y_test, dtype=np.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTePRbqzo0Vl",
        "outputId": "09763e9e-44f6-41b3-ae46-3a53c954cb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c88c4be9abf1>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train = np.array(X_train, dtype=np.float)\n",
            "<ipython-input-20-c88c4be9abf1>:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_train = np.array(y_train, dtype=np.float)\n",
            "<ipython-input-20-c88c4be9abf1>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_test = np.array(X_test, dtype=np.float)\n",
            "<ipython-input-20-c88c4be9abf1>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_test = np.array(y_test, dtype=np.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], X_test[1], y_train[0], y_test[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77SMzNJwo18t",
        "outputId": "11a4b674-b2ad-437d-e4fe-2a98d0a3011e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.08819161, 0.08780668, 0.37595069, 0.34867216, 0.02702703,\n",
              "         0.39828246],\n",
              "        [0.0737454 , 0.13570124, 0.41305946, 0.33308631, 0.02702703,\n",
              "         0.39173046],\n",
              "        [0.10004004, 0.19205717, 0.23423054, 0.16154392, 0.17567568,\n",
              "         0.41367205],\n",
              "        ...,\n",
              "        [0.22628603, 0.24458153, 0.25578897, 0.2112422 , 0.15830116,\n",
              "         0.26289982],\n",
              "        [0.22628603, 0.24458153, 0.25578897, 0.2112422 , 0.15830116,\n",
              "         0.26289982],\n",
              "        [0.22628603, 0.24458153, 0.25578897, 0.2112422 , 0.15830116,\n",
              "         0.26289982]]),\n",
              " array([[0.85894157, 0.8565143 , 0.57951879, 0.2112422 , 0.05984556,\n",
              "         0.14214491],\n",
              "        [0.61402119, 0.57281888, 0.44628064, 0.2112422 , 0.01544402,\n",
              "         0.20903628],\n",
              "        [0.48197771, 0.41604404, 0.16990868, 0.2112422 , 0.01544402,\n",
              "         0.30464979],\n",
              "        ...,\n",
              "        [0.17265129, 0.22430617, 0.49752608, 0.58040143, 0.3030888 ,\n",
              "         0.36323687],\n",
              "        [0.2205519 , 0.27922526, 0.52120501, 0.5997122 , 0.33011583,\n",
              "         0.43812777],\n",
              "        [0.32585721, 0.35426006, 0.49222483, 0.61176918, 0.32432432,\n",
              "         0.34929482]]),\n",
              " array([[ 73.99, 158.2 ,   7.37,  25.22,   0.83,  38.47],\n",
              "        [ 73.99, 158.2 ,   7.37,  25.22,   0.83,  38.47],\n",
              "        [ 73.99, 158.2 ,   7.37,  25.22,   0.83,  38.47],\n",
              "        ...,\n",
              "        [ 40.13, 137.2 ,   6.94,  34.27,   0.97,  47.45],\n",
              "        [ 45.98, 125.6 ,   6.8 ,  33.22,   1.58,  47.74],\n",
              "        [ 70.  ,  80.6 ,   5.05,  36.68,   0.88,  46.92]]),\n",
              " array([[1.1883e+02, 2.5550e+02, 1.0210e+01, 6.0710e+01, 1.8000e-01,\n",
              "         4.8800e+01],\n",
              "        [1.0389e+02, 2.2180e+02, 1.0030e+01, 5.8870e+01, 2.6000e-01,\n",
              "         5.0630e+01],\n",
              "        [8.0760e+01, 1.7560e+02, 7.0800e+00, 5.5270e+01, 4.6000e-01,\n",
              "         6.1420e+01],\n",
              "        ...,\n",
              "        [6.9140e+01, 1.5420e+02, 1.2200e+01, 5.4380e+01, 3.8000e-01,\n",
              "         9.9540e+01],\n",
              "        [6.3800e+01, 1.3200e+02, 1.1930e+01, 5.4810e+01, 1.0900e+00,\n",
              "         8.2760e+01],\n",
              "        [7.9080e+01, 1.5930e+02, 1.1610e+01, 5.5640e+01, 1.1900e+00,\n",
              "         9.1660e+01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tt(nn.Module):\n",
        "    def __init__(self,\n",
        "                 seq_len,\n",
        "                 feature_size,\n",
        "                 output_size,\n",
        "                 device,\n",
        "                 use_model='lstm',\n",
        "                 hidden_size=576,\n",
        "                 num_hidden_layers=6,\n",
        "                 num_attention_heads=6,\n",
        "                 intermediate_size=3072,\n",
        "                 hidden_act=\"gelu\",\n",
        "                 hidden_dropout_prob=0.1,\n",
        "                 attention_probs_dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                #  max_1=25,\n",
        "                #  max_2=61,\n",
        "                #  max_3=8,\n",
        "                #  max_4=1441\n",
        "                 ):\n",
        "        super(Tt, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.use_model = use_model\n",
        "        self.feature_size = feature_size\n",
        "\n",
        "        # If there is a corresponding time embedding, it can be used\n",
        "        # self.th_embeddings = nn.Embedding(max_hour, hidden_size)\n",
        "        # self.tm_embeddings = nn.Embedding(max_min, hidden_size)\n",
        "        # self.td_embeddings = nn.Embedding(max_dow, hidden_size)\n",
        "        # self.tt_embeddings = nn.Embedding(max_ts, hidden_size)\n",
        "\n",
        "        # location code\n",
        "        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_size).to(self.device)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size).to(self.device)\n",
        "        self.fc_inputs = nn.Linear(feature_size, hidden_size).to(self.device)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            hidden_size,\n",
        "            num_attention_heads,\n",
        "            intermediate_size,\n",
        "            dropout=hidden_dropout_prob,\n",
        "            activation=hidden_act)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_hidden_layers).to(self.device)\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=2).to(self.device)\n",
        "\n",
        "        self.fc_output_1 = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
        "        self.fc_output_2 = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
        "        self.fc_output_3 = nn.Linear(hidden_size, output_size).to(self.device)\n",
        "\n",
        "    def forward(self,\n",
        "                inputs,\n",
        "                # inputs_th=None,\n",
        "                # inputs_tm=None,\n",
        "                # inputs_td=None,\n",
        "                # inputs_tt=None,\n",
        "                position_ids=None,\n",
        "                attention_mask=None):\n",
        "\n",
        "        if position_ids is None:\n",
        "            # print(inputs.shape[:2])\n",
        "            ones = torch.ones(inputs.size()[:2], dtype=torch.long, device=self.device)\n",
        "            seq_length = torch.cumsum(ones, axis=1)\n",
        "            # seq_length = torch.mean(seq_length, axis=1)\n",
        "            position_ids = seq_length - ones\n",
        "            position_ids.stop_gradient = True\n",
        "        \n",
        "        # print(\"positionids\",position_ids.size())\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "\n",
        "        # print(self.fc_inputs.weight.dtype)\n",
        "        inputs = self.fc_inputs(inputs)\n",
        "        inputs = nn.Tanh()(inputs)\n",
        "\n",
        "        #print(position_embeddings.size())\n",
        "        inputs = inputs + position_embeddings\n",
        "\n",
        "        # # If there is a corresponding time embedding, it can be used\n",
        "        # if inputs_th is not None:\n",
        "        #     inputs += self.th_embeddings(inputs_th)\n",
        "        \n",
        "        # if inputs_tm is not None:\n",
        "        #     inputs += self.tm_embeddings(inputs_tm)\n",
        "\n",
        "        # if inputs_td is not None:\n",
        "        #     inputs += self.td_embeddings(inputs_td)\n",
        "\n",
        "        # if inputs_tt is not None:\n",
        "        #     inputs += self.tt_embeddings(inputs_tt)\n",
        "\n",
        "        inputs = self.layer_norm(inputs)\n",
        "\n",
        "        # Choose to use LSTM or Transformer\n",
        "        if self.use_model == 'lstm':\n",
        "            encoder_outputs, (h, c) = self.lstm(inputs)\n",
        "        elif self.use_model == 'transformer':\n",
        "            if attention_mask is None:\n",
        "                attention_mask = torch.unsqueeze(\n",
        "                    (torch.zeros(inputs.shape[:2])).astype(\n",
        "                        self.fc_inputs.weight.dtype) * -1e4,\n",
        "                    axis=[1, 2])\n",
        "\n",
        "            encoder_outputs = self.encoder(\n",
        "                inputs,\n",
        "                src_mask=attention_mask)\n",
        "\n",
        "        output = self.fc_output_1(encoder_outputs)\n",
        "        output = nn.ReLU()(output)\n",
        "        output = self.fc_output_2(output)\n",
        "        output = self.fc_output_3(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "m9OWoFpco3ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 168\n",
        "FEATURE_SIZE = 6\n",
        "OUTPUT_SIZE = 6\n",
        "model = Tt(seq_len=SEQ_LEN, feature_size=FEATURE_SIZE, output_size=OUTPUT_SIZE, device=DEVICE)"
      ],
      "metadata": {
        "id": "UefWotQwo8--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((64, 168, 6))\n",
        "# x_numpy = x.detach().numpy()\n",
        "y = model(inputs=x.to(DEVICE))\n",
        "y.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgsdKTzyo_Ja",
        "outputId": "bc3588ca-0ebf-49e5-f616-c2a82616a3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 168, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xt = torch.ones(x_numpy.shape[:2], dtype=torch.long)\n",
        "y.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4-AZXtEpG_e",
        "outputId": "aee2c431-9e81-4201-fc4e-2cebc23b5430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 168, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_score(y_true, y_pred):\n",
        "    y_true = np.nan_to_num(y_true)\n",
        "    y_pred = np.nan_to_num(y_pred)\n",
        "    return 1/ (1+msle(np.clip(np.reshape(y_true, -1), 0, None), np.clip(np.reshape(y_pred, -1), 0, None)))\n",
        "\n",
        "def eval_model(model, data_loader):\n",
        "    model.eval()\n",
        "\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    for step, (data, label) in enumerate(data_loader, start=1):\n",
        "        # print(batch)\n",
        "        # print(batch[0].shape)\n",
        "        data = data.to(torch.float32).to(DEVICE)\n",
        "        label = label.to(torch.float32).to(DEVICE)\n",
        "\n",
        "        # Computational model output\n",
        "        output = model(inputs=data)\n",
        "        y_pred.extend(output.cpu().detach().numpy())\n",
        "        y_true.extend(label.cpu().detach().numpy())\n",
        "    \n",
        "    score = calc_score(y_true, y_pred)\n",
        "    model.train()\n",
        "    return score\n",
        "\n",
        "# def make_data_loader(data_x, idx, batch_size, data_y=None, shuffle=False):\n",
        "#     data = [{'data': torch.Tensor(data_x[i]), 'label': 0 if data_y is None else data_y[i]} for i in idx]\n",
        "#     ds = MapDataset(data)\n",
        "#     batch_sampler = BatchSampler(ds, batch_size=batch_size, shuffle=shuffle)\n",
        "#     return DataLoader(dataset=ds, batch_sampler=batch_sampler)"
      ],
      "metadata": {
        "id": "Xk7DjJKppKA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, X=X_train, y=y_train):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      return torch.tensor(self.X[index], requires_grad=True).type(torch.float), torch.tensor(self.y[index], requires_grad=True).type(torch.float)"
      ],
      "metadata": {
        "id": "tc2eiyPnpL8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EttbQW2npPbV",
        "outputId": "7bb7cc72-be22-403e-a62e-587566cdbdb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17480"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset()\n",
        "x, y = dataset[0]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdThEGs1pRbI",
        "outputId": "620b981f-04bd-4296-f425-7741176b4c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0882, 0.0878, 0.3760, 0.3487, 0.0270, 0.3983],\n",
              "        [0.0737, 0.1357, 0.4131, 0.3331, 0.0270, 0.3917],\n",
              "        [0.1000, 0.1921, 0.2342, 0.1615, 0.1757, 0.4137],\n",
              "        ...,\n",
              "        [0.2263, 0.2446, 0.2558, 0.2112, 0.1583, 0.2629],\n",
              "        [0.2263, 0.2446, 0.2558, 0.2112, 0.1583, 0.2629],\n",
              "        [0.2263, 0.2446, 0.2558, 0.2112, 0.1583, 0.2629]],\n",
              "       grad_fn=<ToCopyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10 # 30 epochs they used\n",
        "BATCH_SIZE = 256\n",
        "CKPT_DIR = 'work/output'\n",
        "K_FOLD = 5\n",
        "epoch_base = 0\n",
        "step_eval = 1\n",
        "step_log = 1\n",
        "\n",
        "def do_train(X_train, y_train, prefix):\n",
        "    print('-'*5)\n",
        "    print('training ...', prefix)\n",
        "    print('train x:', X_train.shape, 'train y:', y_train.shape)\n",
        "\n",
        "    torch.manual_seed(2022)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    for kfold, tv_idx in enumerate(KFold(n_splits=K_FOLD, shuffle=True, random_state=2022).split(X_train)):\n",
        "        print('training fold...', kfold)\n",
        "\n",
        "        train_idx, valid_idx = tv_idx\n",
        "\n",
        "        model = Tt(seq_len=SEQ_LEN, feature_size=FEATURE_SIZE, output_size=OUTPUT_SIZE, device=DEVICE)\n",
        "        model = model.to(device)\n",
        "\n",
        "        # Assuming BATCH_SIZE is defined somewhere else in the code\n",
        "        train_dataset = CustomDataset(X_train, y_train)\n",
        "        valid_dataset = CustomDataset(X_test, y_test)        \n",
        "\n",
        "        # train_dataset = MyDataset(train_x[train_idx], train_y[train_idx])\n",
        "        # valid_dataset = MyDataset(train_x[valid_idx], train_y[valid_idx])\n",
        "\n",
        "        train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        valid_data_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        epochs = EPOCHS # training rounds\n",
        "        save_dir = CKPT_DIR #Folder to save model parameters during training\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        global_step = 0 #iterations\n",
        "        tic_train = time.time()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        best_score = 0\n",
        "        for epoch in range(1+epoch_base, epochs+epoch_base+1):\n",
        "            for step, (data, label) in enumerate(train_data_loader, start=1):\n",
        "                data = data.to(torch.float32).to(device)\n",
        "                label = label.to(device)\n",
        "\n",
        "                # Computational model output\n",
        "                # print(data.dtype)\n",
        "                output = model(inputs=data)\n",
        "                loss = criterion(output, label)\n",
        "                # print(loss)\n",
        "\n",
        "                # Print loss function value, accuracy rate, calculation speed\n",
        "                global_step += 1\n",
        "                if global_step % step_eval == 0:\n",
        "                    score = eval_model(model, valid_data_loader)            \n",
        "                    if score > best_score:\n",
        "                        # print('saving best model...', score)\n",
        "                        save_path = os.path.join(save_dir, f'{prefix}_kfold_{kfold}_best_model.pth')\n",
        "                        torch.save(model.state_dict(), save_path)\n",
        "                        best_score = score\n",
        "                    if global_step % step_log == 0:\n",
        "                        print(\n",
        "                            'global step %d, epoch: %d, batch: %d, loss: %.5f, valid score: %.5f, speed: %.2f step/s'\n",
        "                            % (global_step, epoch, step, loss.item(), score,\n",
        "                                10 / (time.time() - tic_train)))\n",
        "                        tic_train = time.time()\n",
        "\n",
        "                # Reverse gradient return, update parameters\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "# class Tt(nn.Module):\n",
        "#     def __init__(self, seq_len, feature_size, output_size):\n",
        "#         super(Tt, self).__init__()\n",
        "#         self.seq_len = seq_len\n",
        "#         self.feature_size = feature_size\n",
        "#         self.output_size = output_size\n",
        "\n",
        "#         self.fc1 = nn.Linear(seq_len * feature_size, 512)\n",
        "#         self.fc2 = nn.Linear(512, 256)\n",
        "#         self.fc3 = nn.Linear(256, output_size)\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#         x = inputs.view(-1, self.seq_len * self.feature_size)\n"
      ],
      "metadata": {
        "id": "g1wZdyR_pS3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_pred(test_x, prefix):\n",
        "    print('-'*6)\n",
        "    print('predict ...', prefix)\n",
        "    print('predict x:', test_x.shape)\n",
        "\n",
        "    # predict\n",
        "    test_dataset = CustomDataset(X_test,y_test)\n",
        "    test_data_loader = DataLoader(test_dataset, BATCH_SIZE, pin_memory=True, num_workers = 2)\n",
        "\n",
        "    sub_df = []\n",
        "    save_dir = CKPT_DIR\n",
        "\n",
        "    for kfold in range(K_FOLD):\n",
        "        print('predict kfold...', kfold)\n",
        "        model = Tt(seq_len=SEQ_LEN, feature_size=FEATURE_SIZE, output_size=OUTPUT_SIZE, device=DEVICE)\n",
        "        model.load_state_dict(torch.load(os.path.join(save_dir, '{}_kfold_{}_best_model.pth'.format(prefix, kfold))))\n",
        "        model = model.to(DEVICE)\n",
        "        model.eval()\n",
        "\n",
        "        y_pred = []\n",
        "        with torch.no_grad():\n",
        "            for step, (data, label) in enumerate(test_data_loader, start=1):\n",
        "                data = data.to(torch.float).to(DEVICE)\n",
        "                label = label.to(torch.float).to(DEVICE)\n",
        "\n",
        "                # Computational model output\n",
        "                output = model(inputs=data)\n",
        "                y_pred.extend(output.cpu().numpy())\n",
        "\n",
        "        sub_df.append(np.clip(y_pred, 0, None))\n",
        "\n",
        "    return sub_df\n"
      ],
      "metadata": {
        "id": "BOJ1PQrfpZkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model corresponding to each test set in turn\n",
        "do_train(X_train, y_train, 'm1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InVsmLS3pcEm",
        "outputId": "63211a8d-d81b-4211-f12f-b58cd6908e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "training ... m1\n",
            "train x: (17480, 168, 6) train y: (17480, 168, 6)\n",
            "training fold... 0\n",
            "global step 1, epoch: 1, batch: 1, loss: 9461.26465, valid score: 0.07532, speed: 1.51 step/s\n",
            "global step 2, epoch: 1, batch: 2, loss: 9205.20508, valid score: 0.07555, speed: 1.37 step/s\n",
            "global step 3, epoch: 1, batch: 3, loss: 9730.97266, valid score: 0.07590, speed: 1.43 step/s\n",
            "global step 4, epoch: 1, batch: 4, loss: 9878.49121, valid score: 0.07629, speed: 1.45 step/s\n",
            "global step 5, epoch: 1, batch: 5, loss: 9693.14941, valid score: 0.07670, speed: 1.40 step/s\n",
            "global step 6, epoch: 1, batch: 6, loss: 9772.27051, valid score: 0.07717, speed: 1.35 step/s\n",
            "global step 7, epoch: 1, batch: 7, loss: 9179.75879, valid score: 0.07770, speed: 1.37 step/s\n",
            "global step 8, epoch: 1, batch: 8, loss: 9684.18066, valid score: 0.07834, speed: 1.40 step/s\n",
            "global step 9, epoch: 1, batch: 9, loss: 9526.07812, valid score: 0.07912, speed: 1.36 step/s\n",
            "global step 10, epoch: 1, batch: 10, loss: 9872.28223, valid score: 0.08008, speed: 1.35 step/s\n",
            "global step 11, epoch: 1, batch: 11, loss: 9130.37109, valid score: 0.08126, speed: 1.35 step/s\n",
            "global step 12, epoch: 1, batch: 12, loss: 9083.94043, valid score: 0.08273, speed: 1.36 step/s\n",
            "global step 13, epoch: 1, batch: 13, loss: 9232.61426, valid score: 0.08458, speed: 1.32 step/s\n",
            "global step 14, epoch: 1, batch: 14, loss: 9796.72363, valid score: 0.08694, speed: 1.29 step/s\n",
            "global step 15, epoch: 1, batch: 15, loss: 9391.26855, valid score: 0.08994, speed: 1.28 step/s\n",
            "global step 16, epoch: 1, batch: 16, loss: 8950.05371, valid score: 0.09379, speed: 1.25 step/s\n",
            "global step 17, epoch: 1, batch: 17, loss: 8508.26465, valid score: 0.09876, speed: 1.25 step/s\n",
            "global step 18, epoch: 1, batch: 18, loss: 9021.02246, valid score: 0.10513, speed: 1.26 step/s\n",
            "global step 19, epoch: 1, batch: 19, loss: 9546.82422, valid score: 0.11309, speed: 1.26 step/s\n",
            "global step 20, epoch: 1, batch: 20, loss: 8941.65234, valid score: 0.12277, speed: 1.26 step/s\n",
            "global step 21, epoch: 1, batch: 21, loss: 8872.08789, valid score: 0.13414, speed: 1.24 step/s\n",
            "global step 22, epoch: 1, batch: 22, loss: 8785.41699, valid score: 0.14694, speed: 1.28 step/s\n",
            "global step 23, epoch: 1, batch: 23, loss: 7881.89453, valid score: 0.16089, speed: 1.29 step/s\n",
            "global step 24, epoch: 1, batch: 24, loss: 8804.40820, valid score: 0.17579, speed: 1.28 step/s\n",
            "global step 25, epoch: 1, batch: 25, loss: 8557.82715, valid score: 0.19146, speed: 1.29 step/s\n",
            "global step 26, epoch: 1, batch: 26, loss: 8724.97461, valid score: 0.20788, speed: 1.26 step/s\n",
            "global step 27, epoch: 1, batch: 27, loss: 8988.73828, valid score: 0.22511, speed: 1.28 step/s\n",
            "global step 28, epoch: 1, batch: 28, loss: 8341.25488, valid score: 0.24328, speed: 1.28 step/s\n",
            "global step 29, epoch: 1, batch: 29, loss: 8552.45508, valid score: 0.26250, speed: 1.28 step/s\n",
            "global step 30, epoch: 1, batch: 30, loss: 8174.38721, valid score: 0.28279, speed: 1.27 step/s\n",
            "global step 31, epoch: 1, batch: 31, loss: 7793.14258, valid score: 0.30417, speed: 1.23 step/s\n",
            "global step 32, epoch: 1, batch: 32, loss: 7369.09814, valid score: 0.32657, speed: 1.27 step/s\n",
            "global step 33, epoch: 1, batch: 33, loss: 6911.46973, valid score: 0.34987, speed: 1.22 step/s\n",
            "global step 34, epoch: 1, batch: 34, loss: 6976.21240, valid score: 0.37391, speed: 1.26 step/s\n",
            "global step 35, epoch: 1, batch: 35, loss: 6641.85107, valid score: 0.39857, speed: 1.27 step/s\n",
            "global step 36, epoch: 1, batch: 36, loss: 6323.79150, valid score: 0.42367, speed: 1.27 step/s\n",
            "global step 37, epoch: 1, batch: 37, loss: 6072.38916, valid score: 0.44904, speed: 1.27 step/s\n",
            "global step 38, epoch: 1, batch: 38, loss: 6439.31592, valid score: 0.47454, speed: 1.23 step/s\n",
            "global step 39, epoch: 1, batch: 39, loss: 6016.24951, valid score: 0.50008, speed: 1.27 step/s\n",
            "global step 40, epoch: 1, batch: 40, loss: 5934.15332, valid score: 0.52551, speed: 1.24 step/s\n",
            "global step 41, epoch: 1, batch: 41, loss: 5976.52783, valid score: 0.55048, speed: 1.27 step/s\n",
            "global step 42, epoch: 1, batch: 42, loss: 5805.61523, valid score: 0.57415, speed: 1.23 step/s\n",
            "global step 43, epoch: 1, batch: 43, loss: 4989.72363, valid score: 0.59495, speed: 1.24 step/s\n",
            "global step 44, epoch: 1, batch: 44, loss: 4800.74023, valid score: 0.61059, speed: 1.28 step/s\n",
            "global step 45, epoch: 1, batch: 45, loss: 4042.40796, valid score: 0.61958, speed: 1.26 step/s\n",
            "global step 46, epoch: 1, batch: 46, loss: 4214.70557, valid score: 0.62465, speed: 1.30 step/s\n",
            "global step 47, epoch: 1, batch: 47, loss: 3844.95557, valid score: 0.63207, speed: 1.30 step/s\n",
            "global step 48, epoch: 1, batch: 48, loss: 3875.14478, valid score: 0.64490, speed: 1.30 step/s\n",
            "global step 49, epoch: 1, batch: 49, loss: 3524.86035, valid score: 0.65963, speed: 1.29 step/s\n",
            "global step 50, epoch: 1, batch: 50, loss: 3578.95923, valid score: 0.67102, speed: 1.26 step/s\n",
            "global step 51, epoch: 1, batch: 51, loss: 3590.94263, valid score: 0.67594, speed: 1.27 step/s\n",
            "global step 52, epoch: 1, batch: 52, loss: 2693.63916, valid score: 0.67508, speed: 1.33 step/s\n",
            "global step 53, epoch: 1, batch: 53, loss: 2920.07349, valid score: 0.67157, speed: 1.35 step/s\n",
            "global step 54, epoch: 1, batch: 54, loss: 3257.04224, valid score: 0.66876, speed: 1.34 step/s\n",
            "global step 55, epoch: 1, batch: 55, loss: 2804.61792, valid score: 0.66863, speed: 1.34 step/s\n",
            "global step 56, epoch: 1, batch: 56, loss: 2560.07959, valid score: 0.67128, speed: 1.34 step/s\n",
            "global step 57, epoch: 1, batch: 57, loss: 2351.87109, valid score: 0.67574, speed: 1.33 step/s\n",
            "global step 58, epoch: 1, batch: 58, loss: 2631.49609, valid score: 0.67966, speed: 1.27 step/s\n",
            "global step 59, epoch: 1, batch: 59, loss: 2628.14258, valid score: 0.68045, speed: 1.29 step/s\n",
            "global step 60, epoch: 1, batch: 60, loss: 2602.85889, valid score: 0.67841, speed: 1.36 step/s\n",
            "global step 61, epoch: 1, batch: 61, loss: 2524.10156, valid score: 0.67846, speed: 1.33 step/s\n",
            "global step 62, epoch: 1, batch: 62, loss: 2724.71753, valid score: 0.68325, speed: 1.31 step/s\n",
            "global step 63, epoch: 1, batch: 63, loss: 2549.82812, valid score: 0.68816, speed: 1.30 step/s\n",
            "global step 64, epoch: 1, batch: 64, loss: 2628.89111, valid score: 0.68923, speed: 1.28 step/s\n",
            "global step 65, epoch: 1, batch: 65, loss: 2581.07202, valid score: 0.68662, speed: 1.35 step/s\n",
            "global step 66, epoch: 1, batch: 66, loss: 2538.44580, valid score: 0.68314, speed: 1.34 step/s\n",
            "global step 67, epoch: 1, batch: 67, loss: 2547.80200, valid score: 0.68139, speed: 1.35 step/s\n",
            "global step 68, epoch: 1, batch: 68, loss: 2587.72144, valid score: 0.68188, speed: 1.32 step/s\n",
            "global step 69, epoch: 1, batch: 69, loss: 2923.55371, valid score: 0.68401, speed: 1.37 step/s\n",
            "global step 70, epoch: 2, batch: 1, loss: 2575.47827, valid score: 0.68672, speed: 1.39 step/s\n",
            "global step 71, epoch: 2, batch: 2, loss: 2683.06348, valid score: 0.68992, speed: 1.29 step/s\n",
            "global step 72, epoch: 2, batch: 3, loss: 2621.32373, valid score: 0.69458, speed: 1.29 step/s\n",
            "global step 73, epoch: 2, batch: 4, loss: 2525.45337, valid score: 0.70149, speed: 1.28 step/s\n",
            "global step 74, epoch: 2, batch: 5, loss: 2522.17017, valid score: 0.70856, speed: 1.31 step/s\n",
            "global step 75, epoch: 2, batch: 6, loss: 2624.24316, valid score: 0.71397, speed: 1.30 step/s\n",
            "global step 76, epoch: 2, batch: 7, loss: 2557.63037, valid score: 0.71735, speed: 1.31 step/s\n",
            "global step 77, epoch: 2, batch: 8, loss: 2650.94897, valid score: 0.71972, speed: 1.30 step/s\n",
            "global step 78, epoch: 2, batch: 9, loss: 2742.96167, valid score: 0.72200, speed: 1.27 step/s\n",
            "global step 79, epoch: 2, batch: 10, loss: 2670.34937, valid score: 0.72421, speed: 1.30 step/s\n",
            "global step 80, epoch: 2, batch: 11, loss: 2428.45923, valid score: 0.72607, speed: 1.26 step/s\n",
            "global step 81, epoch: 2, batch: 12, loss: 2626.40552, valid score: 0.72709, speed: 1.30 step/s\n",
            "global step 82, epoch: 2, batch: 13, loss: 2613.60669, valid score: 0.72718, speed: 1.29 step/s\n",
            "global step 83, epoch: 2, batch: 14, loss: 2438.93262, valid score: 0.72688, speed: 1.35 step/s\n",
            "global step 84, epoch: 2, batch: 15, loss: 2252.07788, valid score: 0.72656, speed: 1.33 step/s\n",
            "global step 85, epoch: 2, batch: 16, loss: 2420.72974, valid score: 0.72631, speed: 1.35 step/s\n",
            "global step 86, epoch: 2, batch: 17, loss: 2640.88403, valid score: 0.72606, speed: 1.34 step/s\n",
            "global step 87, epoch: 2, batch: 18, loss: 2530.76685, valid score: 0.72547, speed: 1.34 step/s\n",
            "global step 88, epoch: 2, batch: 19, loss: 2510.48535, valid score: 0.72476, speed: 1.35 step/s\n",
            "global step 89, epoch: 2, batch: 20, loss: 2455.59473, valid score: 0.72426, speed: 1.34 step/s\n",
            "global step 90, epoch: 2, batch: 21, loss: 2716.25464, valid score: 0.72419, speed: 1.34 step/s\n",
            "global step 91, epoch: 2, batch: 22, loss: 2487.22095, valid score: 0.72441, speed: 1.34 step/s\n",
            "global step 92, epoch: 2, batch: 23, loss: 2453.96997, valid score: 0.72476, speed: 1.35 step/s\n",
            "global step 93, epoch: 2, batch: 24, loss: 2326.95264, valid score: 0.72505, speed: 1.35 step/s\n",
            "global step 94, epoch: 2, batch: 25, loss: 2363.91211, valid score: 0.72512, speed: 1.35 step/s\n",
            "global step 95, epoch: 2, batch: 26, loss: 2337.01123, valid score: 0.72510, speed: 1.35 step/s\n",
            "global step 96, epoch: 2, batch: 27, loss: 2370.96460, valid score: 0.72507, speed: 1.35 step/s\n",
            "global step 97, epoch: 2, batch: 28, loss: 2429.54517, valid score: 0.72492, speed: 1.35 step/s\n",
            "global step 98, epoch: 2, batch: 29, loss: 2415.50244, valid score: 0.72460, speed: 1.34 step/s\n",
            "global step 99, epoch: 2, batch: 30, loss: 2396.29272, valid score: 0.72408, speed: 1.35 step/s\n",
            "global step 100, epoch: 2, batch: 31, loss: 2572.76294, valid score: 0.72351, speed: 1.31 step/s\n",
            "global step 101, epoch: 2, batch: 32, loss: 2321.38379, valid score: 0.72285, speed: 1.33 step/s\n",
            "global step 102, epoch: 2, batch: 33, loss: 2489.60889, valid score: 0.72242, speed: 1.35 step/s\n",
            "global step 103, epoch: 2, batch: 34, loss: 2362.98193, valid score: 0.72229, speed: 1.36 step/s\n",
            "global step 104, epoch: 2, batch: 35, loss: 2475.42114, valid score: 0.72235, speed: 1.35 step/s\n",
            "global step 105, epoch: 2, batch: 36, loss: 2434.56470, valid score: 0.72224, speed: 1.35 step/s\n",
            "global step 106, epoch: 2, batch: 37, loss: 2652.98706, valid score: 0.72193, speed: 1.35 step/s\n",
            "global step 107, epoch: 2, batch: 38, loss: 2763.52100, valid score: 0.72154, speed: 1.34 step/s\n",
            "global step 108, epoch: 2, batch: 39, loss: 2476.85352, valid score: 0.72110, speed: 1.35 step/s\n",
            "global step 109, epoch: 2, batch: 40, loss: 2511.62549, valid score: 0.72059, speed: 1.35 step/s\n",
            "global step 110, epoch: 2, batch: 41, loss: 2634.78589, valid score: 0.72009, speed: 1.34 step/s\n",
            "global step 111, epoch: 2, batch: 42, loss: 2579.41919, valid score: 0.71961, speed: 1.34 step/s\n",
            "global step 112, epoch: 2, batch: 43, loss: 2512.33960, valid score: 0.71927, speed: 1.35 step/s\n",
            "global step 113, epoch: 2, batch: 44, loss: 2440.33276, valid score: 0.71917, speed: 1.34 step/s\n",
            "global step 114, epoch: 2, batch: 45, loss: 2275.07349, valid score: 0.71938, speed: 1.34 step/s\n",
            "global step 115, epoch: 2, batch: 46, loss: 2446.88159, valid score: 0.71979, speed: 1.35 step/s\n",
            "global step 116, epoch: 2, batch: 47, loss: 2498.00952, valid score: 0.72030, speed: 1.34 step/s\n",
            "global step 117, epoch: 2, batch: 48, loss: 2546.21362, valid score: 0.72081, speed: 1.35 step/s\n",
            "global step 118, epoch: 2, batch: 49, loss: 2284.06616, valid score: 0.72123, speed: 1.32 step/s\n",
            "global step 119, epoch: 2, batch: 50, loss: 2368.67676, valid score: 0.72177, speed: 1.36 step/s\n",
            "global step 120, epoch: 2, batch: 51, loss: 2523.18628, valid score: 0.72213, speed: 1.33 step/s\n",
            "global step 121, epoch: 2, batch: 52, loss: 2481.91650, valid score: 0.72247, speed: 1.36 step/s\n",
            "global step 122, epoch: 2, batch: 53, loss: 2386.77075, valid score: 0.72276, speed: 1.35 step/s\n",
            "global step 123, epoch: 2, batch: 54, loss: 2560.06274, valid score: 0.72317, speed: 1.35 step/s\n",
            "global step 124, epoch: 2, batch: 55, loss: 2399.01733, valid score: 0.72366, speed: 1.35 step/s\n",
            "global step 125, epoch: 2, batch: 56, loss: 2630.45728, valid score: 0.72413, speed: 1.34 step/s\n",
            "global step 126, epoch: 2, batch: 57, loss: 2304.15088, valid score: 0.72464, speed: 1.35 step/s\n",
            "global step 127, epoch: 2, batch: 58, loss: 2461.34888, valid score: 0.72513, speed: 1.34 step/s\n",
            "global step 128, epoch: 2, batch: 59, loss: 2613.97144, valid score: 0.72549, speed: 1.35 step/s\n",
            "global step 129, epoch: 2, batch: 60, loss: 2330.29077, valid score: 0.72558, speed: 1.34 step/s\n",
            "global step 130, epoch: 2, batch: 61, loss: 2471.73804, valid score: 0.72563, speed: 1.35 step/s\n",
            "global step 131, epoch: 2, batch: 62, loss: 2385.62476, valid score: 0.72550, speed: 1.35 step/s\n",
            "global step 132, epoch: 2, batch: 63, loss: 2585.81934, valid score: 0.72542, speed: 1.35 step/s\n",
            "global step 133, epoch: 2, batch: 64, loss: 2213.83862, valid score: 0.72527, speed: 1.35 step/s\n",
            "global step 134, epoch: 2, batch: 65, loss: 2524.88257, valid score: 0.72530, speed: 1.34 step/s\n",
            "global step 135, epoch: 2, batch: 66, loss: 2657.57153, valid score: 0.72546, speed: 1.33 step/s\n",
            "global step 136, epoch: 2, batch: 67, loss: 2355.86426, valid score: 0.72555, speed: 1.35 step/s\n",
            "global step 137, epoch: 2, batch: 68, loss: 2482.37500, valid score: 0.72573, speed: 1.35 step/s\n",
            "global step 138, epoch: 2, batch: 69, loss: 2252.78052, valid score: 0.72589, speed: 1.37 step/s\n",
            "global step 139, epoch: 3, batch: 1, loss: 2701.61011, valid score: 0.72609, speed: 1.41 step/s\n",
            "global step 140, epoch: 3, batch: 2, loss: 2128.57959, valid score: 0.72597, speed: 1.32 step/s\n",
            "global step 141, epoch: 3, batch: 3, loss: 2434.63843, valid score: 0.72585, speed: 1.35 step/s\n",
            "global step 142, epoch: 3, batch: 4, loss: 2419.55200, valid score: 0.72564, speed: 1.35 step/s\n",
            "global step 143, epoch: 3, batch: 5, loss: 2640.41187, valid score: 0.72551, speed: 1.36 step/s\n",
            "global step 144, epoch: 3, batch: 6, loss: 2404.14722, valid score: 0.72529, speed: 1.34 step/s\n",
            "global step 145, epoch: 3, batch: 7, loss: 2558.73267, valid score: 0.72501, speed: 1.34 step/s\n",
            "global step 146, epoch: 3, batch: 8, loss: 2464.97437, valid score: 0.72476, speed: 1.35 step/s\n",
            "global step 147, epoch: 3, batch: 9, loss: 2504.84863, valid score: 0.72447, speed: 1.34 step/s\n",
            "global step 148, epoch: 3, batch: 10, loss: 2454.92188, valid score: 0.72408, speed: 1.36 step/s\n",
            "global step 149, epoch: 3, batch: 11, loss: 2400.59814, valid score: 0.72375, speed: 1.35 step/s\n",
            "global step 150, epoch: 3, batch: 12, loss: 2545.68066, valid score: 0.72366, speed: 1.35 step/s\n",
            "global step 151, epoch: 3, batch: 13, loss: 2466.55615, valid score: 0.72363, speed: 1.35 step/s\n",
            "global step 152, epoch: 3, batch: 14, loss: 2493.19360, valid score: 0.72359, speed: 1.32 step/s\n",
            "global step 153, epoch: 3, batch: 15, loss: 2774.02197, valid score: 0.72343, speed: 1.35 step/s\n",
            "global step 154, epoch: 3, batch: 16, loss: 2605.41455, valid score: 0.72340, speed: 1.34 step/s\n",
            "global step 155, epoch: 3, batch: 17, loss: 2707.72339, valid score: 0.72330, speed: 1.35 step/s\n",
            "global step 156, epoch: 3, batch: 18, loss: 2520.97607, valid score: 0.72314, speed: 1.35 step/s\n",
            "global step 157, epoch: 3, batch: 19, loss: 2588.92578, valid score: 0.72314, speed: 1.36 step/s\n",
            "global step 158, epoch: 3, batch: 20, loss: 2464.73120, valid score: 0.72323, speed: 1.34 step/s\n",
            "global step 159, epoch: 3, batch: 21, loss: 2521.98560, valid score: 0.72336, speed: 1.35 step/s\n",
            "global step 160, epoch: 3, batch: 22, loss: 2334.10767, valid score: 0.72337, speed: 1.33 step/s\n",
            "global step 161, epoch: 3, batch: 23, loss: 2288.82104, valid score: 0.72329, speed: 1.36 step/s\n",
            "global step 162, epoch: 3, batch: 24, loss: 2424.71045, valid score: 0.72321, speed: 1.35 step/s\n",
            "global step 163, epoch: 3, batch: 25, loss: 2278.49536, valid score: 0.72342, speed: 1.35 step/s\n",
            "global step 164, epoch: 3, batch: 26, loss: 2410.93481, valid score: 0.72397, speed: 1.35 step/s\n",
            "global step 165, epoch: 3, batch: 27, loss: 2647.19702, valid score: 0.72450, speed: 1.34 step/s\n",
            "global step 166, epoch: 3, batch: 28, loss: 2403.91064, valid score: 0.72503, speed: 1.36 step/s\n",
            "global step 167, epoch: 3, batch: 29, loss: 2544.81909, valid score: 0.72562, speed: 1.35 step/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1 = do_pred(X_test, 'm1')"
      ],
      "metadata": {
        "id": "QYQTES0BphjY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "adaa6588-117b-4731-b566-669dad9aebf2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-27d2188fc56c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'do_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1"
      ],
      "metadata": {
        "id": "B1Reac4GpiLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSA2J5xTpkkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}